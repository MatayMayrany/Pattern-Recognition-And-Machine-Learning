{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a638a43-a445-420b-9aeb-7b5ec1a86222",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m recognizerScores \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hmmWord \u001b[38;5;129;01min\u001b[39;00m wordsToRecognize:\n\u001b[0;32m---> 75\u001b[0m     recognizerScores[hmmWord] \u001b[38;5;241m=\u001b[39m \u001b[43misolatedWordRecognizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhmmWord\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluateDataPoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataPoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(recognizerScores, key\u001b[38;5;241m=\u001b[39mrecognizerScores\u001b[38;5;241m.\u001b[39mget)\n\u001b[1;32m     78\u001b[0m predictedLabels\u001b[38;5;241m.\u001b[39mappend(predicted)\n",
      "File \u001b[0;32m~/Desktop/kth/Pattern-Recognition-and-Machin-Learning/Assignment_5/IsolatedWordRecognizer.py:93\u001b[0m, in \u001b[0;36mIsolatedWordRecognizer.evaluateDataPoint\u001b[0;34m(self, datapoint)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluateDataPoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, datapoint):\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHMM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogprob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatapoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/kth/Pattern-Recognition-and-Machin-Learning/Assignment_5/PattRecClasses/HMM.py:100\u001b[0m, in \u001b[0;36mHMM.logprob\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogprob\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations):\n\u001b[0;32m--> 100\u001b[0m     res, scaledProbOfObservations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob(observations)\n\u001b[1;32m    101\u001b[0m     alpha, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateGen\u001b[38;5;241m.\u001b[39mforward(scaledProbOfObservations)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(c))\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from IsolatedWordRecognizer import IsolatedWordRecognizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "mfccDataPath = \"mfcc/transform/data/\"\n",
    "\n",
    "wordsToRecognize = [\"yes\", \"down\", \"right\", \"no\", \"left\", \"up\", \"on\", \"off\", \"stop\", \"go\"]\n",
    "isolatedWordRecognizers = {}\n",
    "\n",
    "for word in wordsToRecognize:\n",
    "    isolatedWordRecognizers[word] = IsolatedWordRecognizer(word)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def getTestDataForWord(word):\n",
    "    testDataSet = []\n",
    "    testDirectory = mfccDataPath + word + \"/test/\"\n",
    "    count = 0\n",
    "    for file in os.listdir(testDirectory):\n",
    "        if count < 200:  # settling for 200 data points as that is almost all of them\n",
    "            npyFileName = os.fsdecode(file)\n",
    "            features = np.load(testDirectory + npyFileName)\n",
    "            testDataSet.append(features)\n",
    "            count += 1\n",
    "            \n",
    "    return testDataSet\n",
    "\n",
    "labelAndData = {}\n",
    "for word in wordsToRecognize:\n",
    "        labelAndData[word] = getTestDataForWord(word)\n",
    "        isolatedWordRecognizers[word].loadModel()\n",
    "    \n",
    "correctlyClassified = {\"yes\": 0, \"down\": 0, \"right\": 0, \"no\": 0, \"left\": 0, \"up\": 0, \"on\": 0, \"off\": 0, \"stop\": 0, \"go\": 0}\n",
    "incorrectlyClassified = {\"yes\": 0, \"down\": 0, \"right\": 0, \"no\": 0, \"left\": 0, \"up\": 0, \"on\": 0, \"off\": 0, \"stop\": 0, \"go\": 0}\n",
    "\n",
    "trueLabels = []\n",
    "predictedLabels = []\n",
    "for word in wordsToRecognize:\n",
    "    label = word\n",
    "    data = getTestDataForWord(word)\n",
    "    for dataPoint in data:\n",
    "        trueLabels.append(label)\n",
    "        recognizerScores = {}\n",
    "        for hmmWord in wordsToRecognize:\n",
    "            recognizerScores[hmmWord] = isolatedWordRecognizers[hmmWord].evaluateDataPoint(dataPoint)\n",
    "        \n",
    "        predicted = max(recognizerScores, key=recognizerScores.get)\n",
    "        predictedLabels.append(predicted)\n",
    "        # print(\"label: \", label, \"predicted: \", predicted)\n",
    "        \n",
    "        if predicted == label:\n",
    "            correctlyClassified[label] += 1\n",
    "        else: \n",
    "            incorrectlyClassified[label] += 1\n",
    "\n",
    "print(\"correctly classified: \", correctlyClassified)\n",
    "print(\"incorrectly classified: \", incorrectlyClassified)\n",
    "print(\"true labels: \", len(trueLabels))\n",
    "print(\"predicted labels: \", len(predictedLabels))\n",
    "\n",
    "score = metrics.accuracy_score(trueLabels, predictedLabels)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "cm = metrics.confusion_matrix(trueLabels, predictedLabels)\n",
    "plot_confusion_matrix(cm, classes=wordsToRecognize)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
